{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8519114,"sourceType":"datasetVersion","datasetId":4910211}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rembg==2.0.56","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:27:03.142848Z","iopub.execute_input":"2024-05-31T13:27:03.143417Z","iopub.status.idle":"2024-05-31T13:27:15.445895Z","shell.execute_reply.started":"2024-05-31T13:27:03.143386Z","shell.execute_reply":"2024-05-31T13:27:15.444506Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Requirement already satisfied: rembg==2.0.56 in /opt/conda/lib/python3.10/site-packages (2.0.56)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from rembg==2.0.56) (4.20.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rembg==2.0.56) (1.26.4)\nRequirement already satisfied: onnxruntime in /opt/conda/lib/python3.10/site-packages (from rembg==2.0.56) (1.18.0)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from rembg==2.0.56) (4.9.0.80)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from rembg==2.0.56) (9.5.0)\nRequirement already satisfied: pooch in /opt/conda/lib/python3.10/site-packages (from rembg==2.0.56) (1.8.1)\nRequirement already satisfied: pymatting in /opt/conda/lib/python3.10/site-packages (from rembg==2.0.56) (1.1.12)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from rembg==2.0.56) (0.22.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from rembg==2.0.56) (1.11.4)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from rembg==2.0.56) (4.66.1)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->rembg==2.0.56) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->rembg==2.0.56) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->rembg==2.0.56) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->rembg==2.0.56) (0.16.2)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime->rembg==2.0.56) (15.0.1)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime->rembg==2.0.56) (23.5.26)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime->rembg==2.0.56) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime->rembg==2.0.56) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime->rembg==2.0.56) (1.12)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch->rembg==2.0.56) (4.2.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch->rembg==2.0.56) (2.31.0)\nRequirement already satisfied: numba!=0.49.0 in /opt/conda/lib/python3.10/site-packages (from pymatting->rembg==2.0.56) (0.58.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->rembg==2.0.56) (3.2.1)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->rembg==2.0.56) (2.33.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->rembg==2.0.56) (2023.12.9)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->rembg==2.0.56) (0.3)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba!=0.49.0->pymatting->rembg==2.0.56) (0.41.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime->rembg==2.0.56) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->rembg==2.0.56) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->rembg==2.0.56) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->rembg==2.0.56) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch->rembg==2.0.56) (2024.2.2)\nRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime->rembg==2.0.56) (10.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime->rembg==2.0.56) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom rembg import new_session, remove\n\nfrom skimage.feature import hog\nfrom sklearn.metrics.pairwise import cosine_similarity","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-31T13:27:15.448514Z","iopub.execute_input":"2024-05-31T13:27:15.448905Z","iopub.status.idle":"2024-05-31T13:27:15.459116Z","shell.execute_reply.started":"2024-05-31T13:27:15.448868Z","shell.execute_reply":"2024-05-31T13:27:15.457734Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"class ImageModel:\n    def __init__(self, rgb_img, mask_img, cropped_mask=None, cropped_feature=None, key_contour=None):\n        self.rgb_img = rgb_img                 # Original Img (RGB)\n        self.mask_img = mask_img               # Orignal Img Mask (Binary)\n        self.cropped_mask = cropped_mask       # Cropped Mask (Rotated + Binary)\n        self.cropped_feature = cropped_feature # Cropped Feature (Rotated + Grayscale)\n        self.key_contour = key_contour         # Key Contour","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:27:15.460894Z","iopub.execute_input":"2024-05-31T13:27:15.461233Z","iopub.status.idle":"2024-05-31T13:27:15.467923Z","shell.execute_reply.started":"2024-05-31T13:27:15.461205Z","shell.execute_reply":"2024-05-31T13:27:15.466697Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"INPUT_PATH = '/kaggle/input/key-images/'\n\nfilenames = [file for file in os.listdir(INPUT_PATH) if file[0].isdigit()]\nfilenames.sort()\n\nfilepaths = [os.path.join(INPUT_PATH, file) for file in filenames]\n\nimages = [Image.open(path) for path in filepaths]\n        \nprint(f\"Number of images loaded: {len(images)}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:27:15.470840Z","iopub.execute_input":"2024-05-31T13:27:15.471199Z","iopub.status.idle":"2024-05-31T13:27:15.529515Z","shell.execute_reply.started":"2024-05-31T13:27:15.471170Z","shell.execute_reply":"2024-05-31T13:27:15.528368Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Number of images loaded: 19\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Pipeline","metadata":{}},{"cell_type":"code","source":"def fix_image_size(image):\n    PADDING = 12\n    \n    # Get the original image dimensions\n    original_height, original_width = image.shape[:2]\n\n    dimension = max(original_height, original_width)\n\n    # Create a blank canvas of the desired size\n    canvas = np.zeros((dimension, dimension), dtype=np.uint8)\n\n    # Calculate the offset to center the image on the canvas\n    offset_x = (canvas.shape[1] - image.shape[1]) // 2\n    offset_y = (canvas.shape[0] - image.shape[0]) // 2\n\n    # Paste the resized image onto the canvas\n    canvas[offset_y:offset_y+image.shape[0], offset_x:offset_x+image.shape[1]] = image\n\n    return canvas\n\n\ndef resize_grayscale_image_to_256x256(image):\n    WIDTH = 232\n    HEIGHT = 232\n    PADDING = 12\n    \n    DIMENSION = (WIDTH,HEIGHT,PADDING)\n\n    return resize_grayscale_image(image, DIMENSION)\n\n\ndef resize_grayscale_image(image, dimension):\n    WIDTH, HEIGHT, PADDING = dimension\n    \n    # Get the original image dimensions\n    original_height, original_width = image.shape[:2]\n\n    # Calculate the scaling factor for both dimensions\n    scale_x = WIDTH / original_width\n    scale_y = HEIGHT / original_height\n\n    # Choose the smaller scaling factor to maintain aspect ratio\n    scale = min(scale_x, scale_y)\n\n    # Resize the image using the calculated scaling factor\n    resized_image = cv2.resize(image, None, fx=scale, fy=scale)\n\n    # Create a blank canvas of the desired size\n    canvas = np.zeros((HEIGHT + 2*PADDING, WIDTH + 2*PADDING), dtype=np.uint8)\n\n    # Calculate the offset to center the resized image on the canvas\n    offset_x = (canvas.shape[1] - resized_image.shape[1]) // 2\n    offset_y = (canvas.shape[0] - resized_image.shape[0]) // 2\n\n    # Paste the resized image onto the canvas\n    canvas[offset_y:offset_y+resized_image.shape[0], offset_x:offset_x+resized_image.shape[1]] = resized_image\n    \n    return canvas\n\n\ndef is_ellipse_center_below_lower_half(center, image_shape):\n    center_x, center_y = center\n    image_width, image_height = image_shape\n    return True if (center_y > image_height / 2) else False\n\n\ndef get_rotation_angle(is_below, current_angle):\n    new_angle = 0\n    if current_angle < 90:\n        new_angle = 90 + current_angle\n    elif current_angle > 90 and current_angle < 180:\n        new_angle = current_angle - 90\n    \n    return (new_angle + 180) if is_below else (new_angle + 180)\n\ndef image_processing_pipeline(image_path):\n    # 1. Read img as RGB\n    rgb_img = np.array(image_path)\n\n    # 2. Convert RGB to Grayscale and create an empty img of same dimension\n    grayscale_img = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2GRAY)\n    empty_img = np.zeros_like(grayscale_img, dtype=np.uint8)\n\n    # 3. Convert rgb to mask\n    grayscale_mask = remove_bg(rgb_img, only_mask=True)\n\n    # 4. Convert masked image to binary mask\n    grayscale_mask = np.array(grayscale_mask)\n    _, mask_img = cv2.threshold(grayscale_mask, 127, 255, cv2.THRESH_BINARY)\n\n    # 5. Cropped masked img\n    contours, _ = cv2.findContours(mask_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n    x,y,w,h = cv2.boundingRect(contours[0])\n    cropped_mask = mask_img[y:y+h, x:x+w]\n\n    # 6. Extract and paste only region of interest to grayscale image\n    cv2.drawContours(empty_img, contours, -1, (255), thickness=cv2.FILLED)\n    cropped_feature = cv2.bitwise_and(grayscale_img, grayscale_img, mask=empty_img)\n\n    # 7. Make model object\n    img_model = ImageModel(rgb_img=np.array(rgb_img),\n                           mask_img=mask_img,\n                           cropped_mask=cropped_mask, # Useless\n                           cropped_feature=cropped_feature, # Useless right now\n                           key_contour=contours[0])\n    \n    # 8. Rotate key inside the image by fitting ellipse\n    ellipse = cv2.fitEllipse(img_model.key_contour)\n    center, axis_lengths, current_angle = ellipse\n    is_below = is_ellipse_center_below_lower_half(center, img_model.mask_img.shape)\n    rotation_angle = get_rotation_angle(is_below, current_angle)\n\n    # 9. Resize mask and grayscale image before applying rotation\n    resized_binary_image = fix_image_size(img_model.mask_img)\n    resized_grayscale_image = fix_image_size(img_model.cropped_feature)\n\n    # 10. Apply rotation\n    center = (resized_binary_image.shape[1] // 2, resized_binary_image.shape[0] // 2)\n    rot_mat = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n\n    rotated_binary_image = cv2.warpAffine(resized_binary_image, rot_mat, resized_binary_image.shape[1::-1])\n    rotated_grayscale_image = cv2.warpAffine(resized_grayscale_image, rot_mat, resized_grayscale_image.shape[1::-1])\n\n    # 11. Cropped the rotated masked img\n    contours, _ = cv2.findContours(rotated_binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n    x,y,w,h = cv2.boundingRect(contours[0])\n    rotated_binary_image = rotated_binary_image[y:y+h, x:x+w]\n    rotated_grayscale_image = rotated_grayscale_image[y:y+h, x:x+w]\n\n    # 12. Updated cropped masked\n    img_model.cropped_mask = rotated_binary_image\n    img_model.cropped_feature = rotated_grayscale_image\n    \n    # 13. Resized cropped feature t0 256x256\n    rezised_feature = resize_grayscale_image_to_256x256(img_model.cropped_feature)\n    \n    return img_model, rezised_feature\n\ndef remove_bg(input_img, only_mask=False):\n    '''\n    Remove background for single images\n    '''\n    # Make session\n    session_isnet_general_use = load_general_use_model()\n\n    # Output image\n    output_img = remove(input_img,\n                        session=session_isnet_general_use,\n                        only_mask=only_mask)\n    return output_img\n\n\ndef load_general_use_model(model_name='isnet-general-use'):\n    '''\n    Parameters:\n    model_name: str\n    '''\n    session = new_session(model_name)\n    return session\n\n\ndef plt_contour(contour):\n    # Find the bounding box of the contour\n    x, y, w, h = cv2.boundingRect(contour)\n\n    # Create an empty black image with dimensions based on the bounding box\n    blank_image = np.zeros((h, w, 3), dtype=np.uint8)\n\n    # Draw the contour on the black image with the contour shifted to the top-left corner of the bounding box\n    shifted_contour = contour - np.array([x, y])\n    contour_image = cv2.drawContours(blank_image, [shifted_contour], -1, (0, 0, 255), thickness=cv2.FILLED)\n    \n    plt_img(contour_image)\n    \n    \ndef draw_ellipse(rgb_img, ellipse):\n    center, axis_lengths, current_angle = ellipse\n    \n    # Draw the ellipse on the image\n    cv2.ellipse(rgb_img, ellipse, (0, 255, 0), 5)\n\n    # Draw the center of the ellipse\n    center_point = (int(center[0]), int(center[1]))\n    cv2.circle(rgb_img, center_point, 20, (255, 0, 0), 20)\n\n    # Draw the axis lengths (major and minor axes)\n    major_axis_length = axis_lengths[1] / 2\n    minor_axis_length = axis_lengths[0] / 2\n    \n    # Convert angles to radians for calculation\n    angle_rad = np.deg2rad(current_angle)\n    perpendicular_angle_rad = angle_rad + np.pi / 2\n\n    # Calculate the endpoints of the major axis\n    major_axis_x = int(center[0] + major_axis_length * np.cos(angle_rad))\n    major_axis_y = int(center[1] + major_axis_length * np.sin(angle_rad))\n    cv2.line(rgb_img, center_point, (major_axis_x, major_axis_y), (0, 0, 255), 10)\n\n    # Calculate the endpoints of the minor axis\n    minor_axis_x = int(center[0] - minor_axis_length * np.sin(angle_rad))\n    minor_axis_y = int(center[1] + minor_axis_length * np.cos(angle_rad))\n    cv2.line(rgb_img, center_point, (minor_axis_x, minor_axis_y), (0, 0, 255), 10)\n    \n    # Calculate the rotation matrix\n    rotation_angle = -current_angle\n    rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n\n    # Get the dimensions of the image\n    (h, w) = img_model.rgb_img.shape[:2]\n\n    # Apply the rotation to the image\n    rotated_img = cv2.warpAffine(img_model.rgb_img, rotation_matrix, (w, h))\n\n    return rgb_img, rotated_img\n\n\ndef plt_img(img_data, cmap='viridis'):\n    '''\n    cmap:\n      * 'gray' (Grayscale)\n      * 'binary' (Binary)\n    '''\n    plt.imshow(img_data, cmap=cmap)\n    plt.axis('on')\n    plt.show()","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-05-31T13:27:15.530898Z","iopub.execute_input":"2024-05-31T13:27:15.531211Z","iopub.status.idle":"2024-05-31T13:27:15.567740Z","shell.execute_reply.started":"2024-05-31T13:27:15.531187Z","shell.execute_reply":"2024-05-31T13:27:15.566594Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"# Normalizing Images","metadata":{}},{"cell_type":"code","source":"processed_images = [image_processing_pipeline(image) for image in images]\nprocessed_images = [image[1] for image in processed_images]","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:27:15.569230Z","iopub.execute_input":"2024-05-31T13:27:15.569704Z","iopub.status.idle":"2024-05-31T13:28:45.374825Z","shell.execute_reply.started":"2024-05-31T13:27:15.569641Z","shell.execute_reply":"2024-05-31T13:28:45.373631Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"# Method 1: SIFT","metadata":{}},{"cell_type":"code","source":"def test_sift_on_images(images):\n\n    all_keypoints = []\n    all_descriptors = []\n    sift = cv2.SIFT_create()\n    matcher = cv2.FlannBasedMatcher({'algorithm': 1, 'trees': 10}, {})\n\n    for image in images:\n        keypoints, descriptors = sift.detectAndCompute(image, None)\n        all_keypoints.append(keypoints), all_descriptors.append(descriptors)\n        \n    score_matrix = []\n    MATCH_RATIO = 0.8\n\n    for descriptor1 in all_descriptors:\n\n        row = []\n\n        for descriptor2 in all_descriptors:\n            \n            # Match descriptors using FLANN-based matcher\n            matches = matcher.knnMatch(descriptor1, descriptor2, k=2)\n\n            # Apply ratio test\n            good_matches = []\n            for m, n in matches:\n                if m.distance < MATCH_RATIO * n.distance:\n                    good_matches.append(m)\n\n            row.append(len(good_matches))\n\n        score_matrix.append(row)\n\n    return score_matrix","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:28:45.376250Z","iopub.execute_input":"2024-05-31T13:28:45.376762Z","iopub.status.idle":"2024-05-31T13:28:45.385966Z","shell.execute_reply.started":"2024-05-31T13:28:45.376726Z","shell.execute_reply":"2024-05-31T13:28:45.384517Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"# Method 2: HOG","metadata":{}},{"cell_type":"code","source":"def test_hog_on_images(images):\n    \n    ORT = 8\n    PPC = (8, 8)\n    CPB = (1, 1)\n\n    all_descriptors = []\n    for image in images:\n        descriptors = hog(image, orientations=ORT, pixels_per_cell=PPC, cells_per_block=CPB)\n        all_descriptors.append(descriptors)\n\n    score_matrix = []\n    \n    all_descriptors = all_descriptors\n\n    for descriptor1 in all_descriptors:\n\n        row = []\n\n        for descriptor2 in all_descriptors:\n            score = cosine_similarity([descriptor1], [descriptor2])[0][0]\n            row.append(round(score, 4))\n\n        score_matrix.append(row)\n\n    return score_matrix","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:28:45.388084Z","iopub.execute_input":"2024-05-31T13:28:45.388599Z","iopub.status.idle":"2024-05-31T13:28:45.399354Z","shell.execute_reply.started":"2024-05-31T13:28:45.388551Z","shell.execute_reply":"2024-05-31T13:28:45.398109Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"# Comparison","metadata":{}},{"cell_type":"code","source":"from tabulate import tabulate\n\ndef display_table(data, headers):\n    data.insert(0, [\"\"] + headers)\n    \n    for i in range(1, len(data)):\n        data[i].insert(0, headers[i - 1])\n        \n    table = tabulate(data, headers=\"firstrow\", tablefmt=\"fancy_grid\")\n    print(table)","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:28:45.401169Z","iopub.execute_input":"2024-05-31T13:28:45.402162Z","iopub.status.idle":"2024-05-31T13:28:45.414933Z","shell.execute_reply.started":"2024-05-31T13:28:45.402120Z","shell.execute_reply":"2024-05-31T13:28:45.413908Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"def split_image(image, factor):\n    width = image.shape[1]\n    left = image[:, :int(width * factor)]\n    right = image[:, int(width * factor):]\n    return left, right\n\nleft_images = []\nright_images = []\nfor image in processed_images:\n    split = split_image(image, 0.4)\n    left_images.append(split[0])\n    right_images.append(split[1])","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:28:45.418015Z","iopub.execute_input":"2024-05-31T13:28:45.418392Z","iopub.status.idle":"2024-05-31T13:28:45.428919Z","shell.execute_reply.started":"2024-05-31T13:28:45.418363Z","shell.execute_reply":"2024-05-31T13:28:45.427587Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"scores = test_hog_on_images(left_images[-10:-4])\ndisplay_table(scores, filenames[-10:-4])","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:28:45.430667Z","iopub.execute_input":"2024-05-31T13:28:45.431098Z","iopub.status.idle":"2024-05-31T13:28:45.518215Z","shell.execute_reply.started":"2024-05-31T13:28:45.431068Z","shell.execute_reply":"2024-05-31T13:28:45.517105Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"╒═════════╤═══════════╤═══════════╤═══════════╤═══════════╤══════════╤══════════╕\n│         │   1a.jpeg │   1b.jpeg │   2a.jpeg │   2b.jpeg │   3.jpeg │   4.jpeg │\n╞═════════╪═══════════╪═══════════╪═══════════╪═══════════╪══════════╪══════════╡\n│ 1a.jpeg │    1      │    0.8146 │    0.4552 │    0.4318 │   0.3326 │   0.3839 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 1b.jpeg │    0.8146 │    1      │    0.4824 │    0.4528 │   0.353  │   0.3895 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 2a.jpeg │    0.4552 │    0.4824 │    1      │    0.7571 │   0.457  │   0.5095 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 2b.jpeg │    0.4318 │    0.4528 │    0.7571 │    1      │   0.4896 │   0.5324 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 3.jpeg  │    0.3326 │    0.353  │    0.457  │    0.4896 │   1      │   0.7076 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 4.jpeg  │    0.3839 │    0.3895 │    0.5095 │    0.5324 │   0.7076 │   1      │\n╘═════════╧═══════════╧═══════════╧═══════════╧═══════════╧══════════╧══════════╛\n","output_type":"stream"}]},{"cell_type":"code","source":"scores = test_hog_on_images(right_images[-10:-4])\ndisplay_table(scores, filenames[-10:-4])","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:28:45.519456Z","iopub.execute_input":"2024-05-31T13:28:45.519781Z","iopub.status.idle":"2024-05-31T13:28:45.638996Z","shell.execute_reply.started":"2024-05-31T13:28:45.519754Z","shell.execute_reply":"2024-05-31T13:28:45.637830Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"╒═════════╤═══════════╤═══════════╤═══════════╤═══════════╤══════════╤══════════╕\n│         │   1a.jpeg │   1b.jpeg │   2a.jpeg │   2b.jpeg │   3.jpeg │   4.jpeg │\n╞═════════╪═══════════╪═══════════╪═══════════╪═══════════╪══════════╪══════════╡\n│ 1a.jpeg │    1      │    0.8485 │    0.86   │    0.8397 │   0.736  │   0.6419 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 1b.jpeg │    0.8485 │    1      │    0.8382 │    0.8315 │   0.7019 │   0.6144 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 2a.jpeg │    0.86   │    0.8382 │    1      │    0.8929 │   0.7529 │   0.6498 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 2b.jpeg │    0.8397 │    0.8315 │    0.8929 │    1      │   0.7483 │   0.6718 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 3.jpeg  │    0.736  │    0.7019 │    0.7529 │    0.7483 │   1      │   0.6804 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 4.jpeg  │    0.6419 │    0.6144 │    0.6498 │    0.6718 │   0.6804 │   1      │\n╘═════════╧═══════════╧═══════════╧═══════════╧═══════════╧══════════╧══════════╛\n","output_type":"stream"}]},{"cell_type":"code","source":"scores = test_sift_on_images(left_images[-10:-4])\ndisplay_table(scores, filenames[-10:-4])","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:28:45.640634Z","iopub.execute_input":"2024-05-31T13:28:45.641065Z","iopub.status.idle":"2024-05-31T13:28:45.756801Z","shell.execute_reply.started":"2024-05-31T13:28:45.641028Z","shell.execute_reply":"2024-05-31T13:28:45.755488Z"},"trusted":true},"execution_count":77,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtest_sift_on_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m display_table(scores, filenames[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m])\n","Cell \u001b[0;32mIn[71], line 22\u001b[0m, in \u001b[0;36mtest_sift_on_images\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     17\u001b[0m row \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m descriptor2 \u001b[38;5;129;01min\u001b[39;00m all_descriptors:\n\u001b[1;32m     20\u001b[0m     \n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Match descriptors using FLANN-based matcher\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     matches \u001b[38;5;241m=\u001b[39m \u001b[43mmatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknnMatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescriptor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptor2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Apply ratio test\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     good_matches \u001b[38;5;241m=\u001b[39m []\n","\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/flann/src/miniflann.cpp:521: error: (-215:Assertion failed) (size_t)knn <= index_->size() in function 'runKnnSearch_'\n"],"ename":"error","evalue":"OpenCV(4.9.0) /io/opencv/modules/flann/src/miniflann.cpp:521: error: (-215:Assertion failed) (size_t)knn <= index_->size() in function 'runKnnSearch_'\n","output_type":"error"}]},{"cell_type":"code","source":"scores = test_sift_on_images(right_images[-10:-4])\ndisplay_table(scores, filenames[-10:-4])","metadata":{"execution":{"iopub.status.busy":"2024-05-31T13:36:55.489414Z","iopub.execute_input":"2024-05-31T13:36:55.489930Z","iopub.status.idle":"2024-05-31T13:36:55.632867Z","shell.execute_reply.started":"2024-05-31T13:36:55.489896Z","shell.execute_reply":"2024-05-31T13:36:55.631616Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"╒═════════╤═══════════╤═══════════╤═══════════╤═══════════╤══════════╤══════════╕\n│         │   1a.jpeg │   1b.jpeg │   2a.jpeg │   2b.jpeg │   3.jpeg │   4.jpeg │\n╞═════════╪═══════════╪═══════════╪═══════════╪═══════════╪══════════╪══════════╡\n│ 1a.jpeg │        68 │        26 │        18 │        12 │       12 │       25 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 1b.jpeg │        18 │        62 │         9 │         9 │       11 │       14 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 2a.jpeg │        15 │         6 │        54 │        20 │       10 │       10 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 2b.jpeg │        16 │        10 │        17 │        63 │       11 │       13 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 3.jpeg  │        24 │         9 │        10 │        14 │       73 │        8 │\n├─────────┼───────────┼───────────┼───────────┼───────────┼──────────┼──────────┤\n│ 4.jpeg  │        14 │         6 │         9 │        14 │       11 │       62 │\n╘═════════╧═══════════╧═══════════╧═══════════╧═══════════╧══════════╧══════════╛\n","output_type":"stream"}]}]}